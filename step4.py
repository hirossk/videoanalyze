# å¿…è¦ãªã€Œé­”æ³•ã®é“å…·ç®±ã€ã‚’ä½¿ãˆã‚‹ã‚ˆã†ã«æº–å‚™ã™ã‚‹ãŠã¾ã˜ãªã„
import streamlit as st
import cv2
import numpy as np
import mediapipe as mp

# MediaPipeã¨ã„ã†é“å…·ç®±ã‹ã‚‰ã€ã€Œçµµã‚’æãé“å…·ã€ã¨ã€Œæ‰‹ã‚’è¦‹ã¤ã‘ã‚‹å°‚é–€å®¶ã€ã‚’æº–å‚™
mp_drawing = mp.solutions.drawing_utils
mp_hands = mp.solutions.hands


# --- ã“ã“ã‹ã‚‰Webãƒšãƒ¼ã‚¸ã®è¦‹ãŸç›®ã‚’ä½œã‚‹ ---

# Webãƒšãƒ¼ã‚¸ã«ä¸€ç•ªå¤§ããªã€Œçœ‹æ¿ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ï¼‰ã€ã‚’å‡ºã™
st.title("ğŸ“¹ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ AIè§£æã‚¢ãƒ—ãƒªã‚’ä½œã‚ã†ï¼")
# ç”»é¢ã®å·¦å´ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰ã«ã€Œèª¬æ˜ã€ã‚’è¡¨ç¤ºã™ã‚‹
st.sidebar.markdown("### è§£æãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„")


# --- ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã¨ãã®ã€ŒçŠ¶æ…‹ã€ã‚’è¦šãˆã¦ãŠãä»•çµ„ã¿ ---

# ã‚‚ã—ã€Œmodeã€ã¨ã„ã†åå‰ã®ã€ŒçŠ¶æ…‹ã„ã‚Œã‚‚ã®ã€ãŒãªã‘ã‚Œã°ã€æœ€åˆã«ä½œã£ã¦ãŠã
# æœ€åˆã¯ã€Œæ­¢ã¾ã£ã¦ã„ã‚‹(Stop)ã€çŠ¶æ…‹ã«ã—ã¦ãŠã
if 'mode' not in st.session_state:
    st.session_state['mode'] = 'Stop'

# ã€Œæ‰‹ã®æ¤œå‡ºã€ãƒœã‚¿ãƒ³ã€‚æŠ¼ã•ã‚Œã‚‹ã¨ã€ã€ŒçŠ¶æ…‹ã„ã‚Œã‚‚ã®ã€ã«ã€ŒHandsã€ã¨ã„ã†æ–‡å­—ã‚’å…¥ã‚Œã‚‹
if st.sidebar.button("ğŸ–ï¸ æ‰‹ã®æ¤œå‡º (MediaPipe)"):
    st.session_state['mode'] = 'Hands'

# ã€Œåœæ­¢ã€ãƒœã‚¿ãƒ³ã€‚æŠ¼ã•ã‚Œã‚‹ã¨ã€ã€ŒçŠ¶æ…‹ã„ã‚Œã‚‚ã®ã€ã«ã€ŒStopã€ã¨ã„ã†æ–‡å­—ã‚’å…¥ã‚Œã‚‹
if st.sidebar.button("ğŸ›‘ åœæ­¢"):
    st.session_state['mode'] = 'Stop'

# ä»Šã®çŠ¶æ…‹ï¼ˆãƒ¢ãƒ¼ãƒ‰ï¼‰ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¡¨ç¤ºã™ã‚‹
st.sidebar.markdown(f"**ç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ‰:** `{st.session_state['mode']}`")


# --- ã“ã“ã‹ã‚‰ã‚«ãƒ¡ãƒ©ã®æ˜ åƒã‚’å‡¦ç†ã™ã‚‹ ---

# æ˜ åƒã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ã€Œç©ºã®å ´æ‰€ï¼ˆé¡ç¸ï¼‰ã€ã‚’ãƒšãƒ¼ã‚¸ã«ç”¨æ„ã™ã‚‹
frame_placeholder = st.empty()
# PCã®ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã™ã‚‹
cap = cv2.VideoCapture(0)

# ã€Œæ‰‹ã‚’è¦‹ã¤ã‘ã‚‹å°‚é–€å®¶ã€ã‚’å‘¼ã³å‡ºã—ã¦ã€æº–å‚™ã—ã¦ã‚‚ã‚‰ã†
with mp_hands.Hands(model_complexity=0, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:

    # ã‚«ãƒ¡ãƒ©ãŒèµ·å‹•ã—ã¦ã„ã¦ã€ã‹ã¤ã€Œåœæ­¢ã€ãƒ¢ãƒ¼ãƒ‰ã§ã¯ãªã„é–“ã€ãšã£ã¨ç¹°ã‚Šè¿”ã™
    while cap.isOpened() and st.session_state['mode'] != 'Stop':
        # ã‚«ãƒ¡ãƒ©ã‹ã‚‰1æšã®ç”»åƒ(ãƒ•ãƒ¬ãƒ¼ãƒ )ã‚’èª­ã¿è¾¼ã‚€
        success, image = cap.read()
        if not success:
            break

        # æ˜ åƒã‚’é¡ã®ã‚ˆã†ã«å·¦å³åè»¢ã•ã›ã‚‹
        image = cv2.flip(image, 1)
        # å‡¦ç†ã—ãŸå¾Œã®ç”»åƒã‚’å…¥ã‚Œã‚‹ãŸã‚ã®å¤‰æ•°ã‚’ç”¨æ„
        processed_image = image.copy()
        # æç”»ã‚¨ãƒªã‚¢ã‚’çœŸã£æš—ã«ã™ã‚‹ é»’ã¯0
        # processed_image[:] = 0

        # ç”»åƒã®è‰²ã‚’ã€AIãŒç†è§£ã—ã‚„ã™ã„ã€ŒRGBã€å½¢å¼ã«å¤‰æ›ã™ã‚‹
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # ã‚‚ã—ä»Šã®ãƒ¢ãƒ¼ãƒ‰ãŒã€ŒHandsã€ãªã‚‰ã€æ‰‹ã®æ¤œå‡ºã‚’è¡Œã†
        if st.session_state['mode'] == 'Hands':
            # ã€Œæ‰‹ã‚’è¦‹ã¤ã‘ã‚‹å°‚é–€å®¶ã€ã«ç”»åƒã‚’è¦‹ã›ã¦ã€æ‰‹ã‚’æ¢ã—ã¦ã‚‚ã‚‰ã†
            results = hands.process(image_rgb)
            
            # ã‚‚ã—æ‰‹ãŒè¦‹ã¤ã‹ã£ãŸã‚‰ã€ãã®å ´æ‰€ã«éª¨æ ¼ã‚’æã
            if results.multi_hand_landmarks:
                for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):
                    # æ‰‹ã®éª¨æ ¼ã‚’æã
                    # mp_drawing.draw_landmarks(processed_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)
                    # å„æŒ‡ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                    # finger_names = ['', '', '', '', '']
                    # finger_tips = [4, 8, 12, 16, 20]
                    # h, w, _ = processed_image.shape
                    # for name, tip_idx in zip(finger_names, finger_tips):
                    #     tip = hand_landmarks.landmark[tip_idx]
                    #     x, y = int(tip.x * w), int(tip.y * h)
                    #     cv2.putText(processed_image, name, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)
                # å·¦å³ã®æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’ãã‚Œãã‚Œæã
                # for idx, handedness in enumerate(results.multi_handedness):
                #     label = handedness.classification[0].label  # 'Left' or 'Right'
                #     hand_landmarks = results.multi_hand_landmarks[idx]
                #     h, w, _ = processed_image.shape
                #     # æ‰‹é¦–ã®ä½ç½®ã«å·¦å³ãƒ©ãƒ™ãƒ«ã‚’æç”»
                #     wrist = hand_landmarks.landmark[0]
                #     x, y = int(wrist.x * w), int(wrist.y * h)
                #     cv2.putText(processed_image, label, (x, y-30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255,0,0), 2)
                    pass
        # æº–å‚™ã—ã¦ãŠã„ãŸã€Œç©ºã®å ´æ‰€ï¼ˆé¡ç¸ï¼‰ã€ã«ã€å‡¦ç†ãŒçµ‚ã‚ã£ãŸç”»åƒã‚’è¡¨ç¤ºã™ã‚‹
        frame_placeholder.image(processed_image, channels="BGR")

# ï¼ˆãƒ«ãƒ¼ãƒ—ãŒçµ‚ã‚ã£ãŸã‚‰ï¼‰ä½¿ã„çµ‚ã‚ã£ãŸã‚«ãƒ¡ãƒ©ã‚’è§£æ”¾ã™ã‚‹ï¼ˆãŠç‰‡ä»˜ã‘ï¼‰
cap.release()
cv2.destroyAllWindows()

# ã‚‚ã—ä»Šã®ãƒ¢ãƒ¼ãƒ‰ãŒã€ŒStopã€ãªã‚‰ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹
if st.session_state['mode'] == 'Stop':
    st.success("å‡¦ç†ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")