# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import streamlit as st
import cv2
import mediapipe as mp
import numpy as np

# ã‚¢ãƒã‚¿ãƒ¼ã®å††ã®å¤§ãã•ã¨ç·šã®å¤ªã•ï¼ˆå®šæ•°ã¨ã—ã¦æœ€åˆã«å®šç¾©ï¼‰
AVATAR_CIRCLE_RADIUS = 15  # å††ã®åŠå¾„
AVATAR_LINE_THICKNESS = 10 # ç·šã®å¤ªã•

# MediaPipeã®æº–å‚™
mp_drawing = mp.solutions.drawing_utils
mp_pose = mp.solutions.pose

# --- Streamlit UIã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ---
st.title("ğŸ¤– ãƒãƒ¼ã‚ºã§å‹•ãï¼ãƒ­ãƒœãƒƒãƒˆé¢¨ã‚¢ãƒã‚¿ãƒ¼")
st.sidebar.markdown("### è§£æãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„")

if 'mode' not in st.session_state:
    st.session_state['mode'] = 'Stop'

if st.sidebar.button("ğŸ¤– ã‚¢ãƒã‚¿ãƒ¼è¡¨ç¤º"):
    st.session_state['mode'] = 'Avatar'
if st.sidebar.button("ğŸ›‘ åœæ­¢"):
    st.session_state['mode'] = 'Stop'

# --- ã‚«ãƒ¡ãƒ©å‡¦ç† ---
frame_placeholder = st.empty()
cap = cv2.VideoCapture(0)

with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
    while cap.isOpened() and st.session_state['mode'] != 'Stop':
        success, image = cap.read()
        if not success:
            break

        image = cv2.flip(image, 1)
        # ã‚¢ãƒã‚¿ãƒ¼ã‚’æç”»ã™ã‚‹ãŸã‚ã«ã€å…ƒã®ç”»åƒã¨åŒã˜å¤§ãã•ã®çœŸã£é»’ãªç”»åƒã‚’ç”¨æ„
        avatar_image = np.zeros(image.shape, dtype=np.uint8)

        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = pose.process(image_rgb)

        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            h, w, _ = image.shape

            # --- å„é–¢ç¯€ã«å††ã‚’æç”» ---
            body_parts = [
                mp_pose.PoseLandmark.NOSE, mp_pose.PoseLandmark.LEFT_SHOULDER,
                mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW,
                mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST,
                mp_pose.PoseLandmark.RIGHT_WRIST, mp_pose.PoseLandmark.LEFT_HIP,
                mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.LEFT_KNEE,
                mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.LEFT_ANKLE,
                mp_pose.PoseLandmark.RIGHT_ANKLE
            ]
            for part in body_parts:
                lm = landmarks[part.value]
                cx, cy = int(lm.x * w), int(lm.y * h)
                # cv2.circle(avatar_image, (cx, cy), AVATAR_CIRCLE_RADIUS, (255, 255, 0), -1) # é’ç·‘è‰²ã®å††

            # --- é–¢ç¯€ã‚’ç·šã§çµã¶ ---
            connections = [
                # èƒ´ä½“
                (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER),
                (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_HIP),
                (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_HIP),
                (mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.RIGHT_HIP),
                # è…•
                (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW),
                (mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST),
                (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW),
                (mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST),
                # è„š
                (mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_KNEE),
                (mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_ANKLE),
                (mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_KNEE),
                (mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_ANKLE),
            ]
            for start_node, end_node in connections:
                start_lm = landmarks[start_node.value]
                end_lm = landmarks[end_node.value]
                start_point = (int(start_lm.x * w), int(start_lm.y * h))
                end_point = (int(end_lm.x * w), int(end_lm.y * h))
                # cv2.line(avatar_image, start_point, end_point, (255, 255, 255), AVATAR_LINE_THICKNESS) # ç™½ã„å¤ªç·š

        # å…ƒã®ã‚«ãƒ¡ãƒ©ç”»åƒã¨ã€ä½œæˆã—ãŸã‚¢ãƒã‚¿ãƒ¼ç”»åƒã‚’åˆæˆ
        # 0.7ã¨0.3ã¯ç”»åƒã®é€æ˜åº¦ã€‚æ•°å­—ã‚’å¤‰ãˆã‚‹ã¨ã€ã©ã¡ã‚‰ã‚’æ¿ƒãè¡¨ç¤ºã™ã‚‹ã‹ãŒå¤‰ã‚ã‚‹
        combined_image = cv2.addWeighted(image, 0.7, avatar_image, 0.3, 0)
        
        frame_placeholder.image(combined_image, channels="BGR")

    cap.release()